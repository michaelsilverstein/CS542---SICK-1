{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Load data from all_processed_data.csv\"\n",
    "df = pd.read_csv('all_processed_data.csv')\n",
    "\"Drop all the columns with NaN value\"\n",
    "df = df.dropna()\n",
    "\"Set the gap value to be zero if it's negative\"\n",
    "df.gap[df.gap<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Analysis\"\"\"\n",
    "shuffled = df.sample(frac=1,random_state=1234)\n",
    "\n",
    "weekday_dict = {day:n for day,n in zip(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],range(7))}\n",
    "cols = ['time','height','width','length','volume','weight','angle','gap','velocity','weekday','LFT']\n",
    "shuffled = shuffled[cols]\n",
    "shuffled.weekday = shuffled.weekday.apply(lambda x: weekday_dict[x])\n",
    "# might out put differently for Python v2 and v3\n",
    "idx = np.floor(np.arange(0,len(shuffled),len(shuffled)/5)).astype(int)\n",
    "# idx = list(idx)+[len(shuffled)]    # uncomment this if using Python v3\n",
    "sets = {i:shuffled.iloc[idx[i]:idx[i+1]-1] for i in range(len(idx)-1)}\n",
    "\n",
    "\n",
    "\n",
    "# function compute LDA\n",
    "def lda(train_data, train_labels, test_data, test_labels):\n",
    "    pos = np.array([train_data[i] for i in range(train_data.shape[0]) if train_labels[i] == 1])\n",
    "    neg = np.array([train_data[i] for i in range(train_data.shape[0]) if train_labels[i] == 0])\n",
    "    pos_mean = np.mean(pos,axis=0)\n",
    "    neg_mean = np.mean(neg,axis=0)\n",
    "    pos_data = pos - pos_mean\n",
    "    neg_data = neg - neg_mean\n",
    "    cov_all = np.cov(np.concatenate((pos_data, neg_data), axis=0).T)\n",
    "    w = np.linalg.solve(cov_all,(pos_mean - neg_mean))\n",
    "    # compute x_lda\n",
    "    x_lda = test_data.dot(w)\n",
    "    posm_transform = pos_mean.dot(w.T)\n",
    "    negm_transform = neg_mean.dot(w.T)\n",
    "    y_lda = []\n",
    "    for element in x_lda:\n",
    "        compare_pos = abs(element - posm_transform)\n",
    "        compare_neg = abs(element - negm_transform)\n",
    "        if (compare_pos < compare_neg):\n",
    "            y_lda.append(1)\n",
    "        else:\n",
    "            y_lda.append(0)\n",
    "    # calculate accuracy, precision / recall and F1 score\n",
    "    accuracy = 0\n",
    "    true_positive = 0\n",
    "    predicted_positive = 0\n",
    "    positive = sum(test_labels)\n",
    "    for index, value in enumerate(y_lda):\n",
    "        if value == test_labels[index]:\n",
    "            accuracy += 1\n",
    "        if value == 1:\n",
    "            predicted_positive += 1\n",
    "            if (test_labels[index] == 1):\n",
    "                true_positive += 1\n",
    "    accuracy  = float(accuracy) / len(y_lda)\n",
    "    precision = float(true_positive) / predicted_positive\n",
    "    recall    = float(true_positive) / positive\n",
    "    F1_score  = 2 * (precision * recall) / (precision + recall)\n",
    "    #print(\"accuracy  = {}\".format(accuracy))\n",
    "    #print(\"precision = {}\".format(precision))\n",
    "    #print(\"recall    = {}\".format(recall))\n",
    "    #print(\"F1_score  = {}\\n\".format(F1_score))\n",
    "    return accuracy, precision, recall, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for iteration 0:\n",
      "accuracy  = 0.692113400032\n",
      "precision = 0.958122524502\n",
      "recall    = 0.700270996984\n",
      "F1_score  = 0.80915103294\n",
      "\n",
      "Result for iteration 1:\n",
      "accuracy  = 0.690567394044\n",
      "precision = 0.95702788885\n",
      "recall    = 0.699334249181\n",
      "F1_score  = 0.808135328292\n",
      "\n",
      "Result for iteration 2:\n",
      "accuracy  = 0.692536828423\n",
      "precision = 0.957091638352\n",
      "recall    = 0.701335292749\n",
      "F1_score  = 0.809492576107\n",
      "\n",
      "Result for iteration 3:\n",
      "accuracy  = 0.692522057665\n",
      "precision = 0.957885925413\n",
      "recall    = 0.70101503005\n",
      "F1_score  = 0.809563016497\n",
      "\n",
      "Result for iteration 4:\n",
      "accuracy  = 0.689464510793\n",
      "precision = 0.9580297797\n",
      "recall    = 0.697398515701\n",
      "F1_score  = 0.807197204755\n",
      "\n",
      "accuracy_mean  = 0.691440838191\n",
      "precision_mean = 0.957631551363\n",
      "recall_mean    = 0.699870816933\n",
      "F1_score_mean  = 0.808707831718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "accuracy_mean  = 0\n",
    "precision_mean = 0\n",
    "recall_mean    = 0\n",
    "F1_score_mean  = 0\n",
    "for i in range(len(sets)):\n",
    "    #Training set (leaving out current test set)\n",
    "    train = pd.concat([sets[s] for s in range(len(sets)) if s!=i])\n",
    "    train_data = train[cols]\n",
    "    train_data = np.array(train_data)\n",
    "    train_data = np.delete(train_data, 10, 1)\n",
    "    train_labels = train.LFT\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    #Test set\n",
    "    test = sets[i]\n",
    "    test_data = test[cols]\n",
    "    test_data = np.array(test_data)\n",
    "    test_data = np.delete(test_data, 10, 1)\n",
    "    test_labels = test.LFT\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    \n",
    "    #Run LDA\n",
    "    print(\"Result for iteration {}:\".format(i))\n",
    "    accuracy, precision, recall, F1_score = lda(train_data, train_labels, test_data, test_labels)\n",
    "    print(\"accuracy  = {}\".format(accuracy))\n",
    "    print(\"precision = {}\".format(precision))\n",
    "    print(\"recall    = {}\".format(recall))\n",
    "    print(\"F1_score  = {}\\n\".format(F1_score))\n",
    "    accuracy_mean  += accuracy\n",
    "    precision_mean += precision\n",
    "    recall_mean    += recall\n",
    "    F1_score_mean  += F1_score\n",
    "print(\"accuracy_mean  = {}\".format(accuracy_mean / 5))\n",
    "print(\"precision_mean = {}\".format(precision_mean / 5))\n",
    "print(\"recall_mean    = {}\".format(recall_mean / 5))\n",
    "print(\"F1_score_mean  = {}\\n\".format(F1_score_mean / 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
